---
title: "Hard Work 9"
output: 
  html_document:
    theme: cerulean
    toc: true
    toc_float: true
    code_folding: hide
---

```{r, include=FALSE}
library(leaps)
library(qpcR)
library(mosaic)
```


```{r}
# This function will be useful later on.
makeTable9.3 <- function(thedata, nbest=1){
  
  if (nbest < 1 | nbest > dim(thedata)[2]-1){
    warning("nbest recoded to 1")
    nbest <- 1
  }
  
  cnames <- colnames(thedata)

  Yat <- grep("Y",cnames)
  
  if (length(Yat)>1)
    stop("Currently you have: ", paste(cnames[Yat], ", ", sep=""), 
               " in your data set.\n There can be only one response variable.\n",
               sep="")

  colnames(thedata)[Yat] <- "Y"
  Xat <- grep("X",cnames)
  
  require("leaps")
  require("qpcR")

  reg <- regsubsets(thedata[,Xat],thedata[,Yat], nbest=nbest, nvmax=length(cnames)-1)

  regs <- summary(reg)
  
  models <- sapply(1:length(row.names(regs$which)), function(i){
    colnames(regs$which)[which(regs$which[i,])][-1]
  })
  
  pressdata <<- thedata
  
  PRESS <- sapply(models, function(model){
    tmpf <- formula(paste("Y~",
                          paste(model,
                                c(rep("+",length(model)-1), ""), 
                                sep="", 
                                collapse=""), 
                          sep=""))
    tmp <- lm(tmpf, data=pressdata)
    tmp$call$formula <- eval(tmpf)
    PRESS(tmp, verbose=FALSE)$stat
  })
  
  n <- nrow(thedata)
  p <- as.numeric(row.names(regs$which))+1
 
  
  AIC <- regs$bic-log(n)*p-2*p

  
  AIC2 <- sapply(models, function(model){
    tmpf <- formula(paste("Y~",
                          paste(model,
                                c(rep("+",length(model)-1), ""), 
                                sep="", 
                                collapse=""), 
                          sep=""))
    tmp <- lm(tmpf, data=pressdata)
    tmp$call$formula <- eval(tmpf)
    AIC(tmp)
  })
  
  tmp <- data.frame(p=p, 
             model= sapply(1:length(models), function(i) {
                      paste(models[[i]], collapse=",")
                    }),
             SSEp=regs$rss,
             R2p=regs$rsq,
             R2ap=regs$adjr2,
             Cp=regs$cp,
             AICp=AIC2,
             SBCp=regs$bic,
             PRESSp=PRESS)
  
  rbind(data.frame(p=1,
                   model="(intercept)",
                   SSEp=regs$rss[1]/(1-regs$rsq[1]),
                   R2p=0,
                   R2ap=0,
                   Cp=NA,
                   AICp=NA,
                   SBCp=NA,
                   PRESSp=NA),tmp)
}
```

## Instructions

1. Study Sections 10.1 and 9.1-9.4 -- "Added Variable Plots" and "Criteria for Model Selection."

2. Attempt and submit at least <span id=points style="padding-left:0px;">{36}</span> Hard Work Points by Saturday at 11:59 PM.    
<span id=note>Over <span id=points style="padding-left:0px;">{50}</span> gets you {+1} Final Exam Point.</span>    


## Reading Points <span id=headpoints>{21} Possible</span>

### Section 10.1 <span id=rrecpoints>{4}</span><span id=report>{ 4 / 4 }</span>

### Section 9.1 <span id=rrecpoints>{3}</span><span id=report>{ 3 / 3 }</span>

### Section 9.2 <span id=rrecpoints>{4}</span><span id=report>{ 4 / 4 }</span>

### Section 9.3 <span id=rrecpoints>{6}</span><span id=report>{ 6 / 6 }</span>

### Section 9.4 <span id=rrecpoints>{4}</span><span id=report>{ 4 / 4 }</span>


## Theory Points <span id=headpoints>{3} Possible</span>

<div style="padding-left:20px;">

### Problem 9.6 <span id=points>{3}</span><span id=report>{ /  }</span>
 


## Application Points <span id=headpoints>{28} Possible</span>

<div style="padding-left:20px;">

<a id=datalink style="font-size:.9em;" target="_blank" href=http://www.stat.ufl.edu/~rrandles/sta4210/Rclassnotes/data/textdatasets/index.html>Data Files</a>

### Problem 9.9 <span id=points>{3}</span><span id=report>{ 3 / 3 }</span> 

```{r}
# Code to read in the data
# It has to be merged from the 1.20 and 8.15 data files.
p9.9 <- read.table("http://www.stat.ufl.edu/~rrandles/sta4210/Rclassnotes/data/textdatasets/KutnerData/Chapter%20%206%20Data%20Sets/CH06PR15.txt", header=FALSE)

# Give it nice column names for conevience:
colnames(p9.9) <- c("Y","X1","X2","X3")

# Show the first part of the data:
#head(p9.9)
```

**a.** Indicate which subset of predictor variables you would recommend as best for predicting patient satisfaction according to each of the following criteria.
```{r}
makeTable9.3(p9.9, nbest=3)
```

The "best" subset recommendations. 

| Criteria   | Criteria Score   | Subset      |
|------------|------------------|-------------|
|R2ap        |  0.6610206       | X1, X3      |
|AICp        | 347.6030         | X1, X3      |
|Cp          | 2.807204         | X1, X3      |
|PRESSp      | 4902.751         | X1, X3      |

**b.** Do the four criteria in part (a) identify the same best subset? does this always happen? 

In this case, all four of the criteria support the same subset of variables, however this is not always the case. 

**c.** Would forward step-wise regression have any advantages here as a screening procedure over the all-possible-regression procedure. 

Looking at page 368, it appears that in this case, because the number of predictor variables is small, a backwards step-wise procedure would be more effective because the possibly inflated standard error. So in this case it might be best to use the all-possible-regression procedure. 

In other situations, they are relatively the same and use similar criteria but it is more automated and would produce only one combination of variables instead of a subset of combinations. 

But having a subset of variables would lead to more options to explore. 

```{r}
# Stepwise Regression
library(MASS)
fit <- lm(Y~X1+X3+X2,data=p9.9)
step <- stepAIC(fit, direction="both")
step$anova # display results
```



### Problem 9.10 <span id=recpoints>{3}</span><span id=report>{ 3 / 3 }</span> 

```{r}
# Code to read in the data
# It has to be merged from the 1.20 and 8.15 data files.
p9.10 <- read.table("http://www.stat.ufl.edu/~rrandles/sta4210/Rclassnotes/data/textdatasets/KutnerData/Chapter%20%209%20Data%20Sets/CH09PR10.txt", header=FALSE)

# Give it nice column names for conevience:
colnames(p9.10) <- c("Y","X1","X2","X3","X4")

# Show the first part of the data:
#head(p9.10)
```

**a.** Prepare stem and leaf plots of the test scores for each of the four newly developed aptitude tests. Are there ant noteworthy features in these plots? Comment. 

```{r}
stem(p9.10$X1)
stem(p9.10$X2)
stem(p9.10$X3)
stem(p9.10$X4)
```

X1 seems to be normal, however X2, X3, and X3 aren't so  normal. 

Other than that, there doesn't really appear to be too out of the ordinary. 

**b.** Obtain the scatter plot matrix. Also obtain the correlation matrix of the $X$ variables. What do the scatter plots suggest about the nature of the functional relationship between the response variable $Y$ and each of the predictor variables? Are there any serious mutlicollinearity problems evident? Explain. 

```{r}
pairs(Y~X1+X2+X3+X4, data=p9.10)
```

X3 and X4 really seem to have a strong positive correlation with Y. X1 might be able to help explain Y but it might contain an outlier.   

```{r}
cor(p9.10)
```

There may be an issue with multicollinearity with X3 and X4. It is possible that only one of these variables will be needed in the final model. 

**c.** Fit the multiple regression function containing all four predictor variables as first-order terms. Does it appear that all predictor variables should be retained?  

```{r}
p9.10.lm <- lm(Y ~ X1 + X2 + X3 + X4, data=p9.10)
summary(p9.10.lm)
```

It appears that X3, X1 and X4 are needed. in the model. X2 is not adding much information here. 

Some more exploration could be done. 

```{r}
mylm2 <- lm(Y ~ X3, data=p9.10)
summary(mylm2)
plot(mylm2, which=1:2)
```


```{r}
pairs(cbind(R=mylm2$res, p9.10))

mylm3 <- lm(Y ~ X3 + X1, data=p9.10)
summary(mylm3)
plot(mylm3, which=1:2)
```

```{r}
pairs(cbind(R=mylm3$res, p9.10))
```

```{r}
makeTable9.3(p9.10)
```

```{r}
mylm4 <- lm(Y ~ X3 + X1 +X4, data=p9.10)
summary(mylm4)
plot(mylm4, which=1:2)
```


### Problem 9.11 <span id=recpoints>{2}</span><span id=report>{ 2 / 2 }</span> 

```{r}
# Use the data p9.10 for this one.
```

**a.** Using only first order terms for the predictor variables in the pool of potential X variables, find the four best subset regression models according to the R2ap criterion. 

```{r}
makeTable9.3(p9.10, nbest=8)
```

| Subset            |  R^2_ap   |
|-------------------|-----------|
|X1, X3, X4         | 0.9560482 | 
|X1, X2, X3, X4     | 0.9554702 |
|X1, X3             | 0.9269043 |
|X1, X2, X3         | 0.9246779 |

**b.** Since there is relatively little difference in R2ap for the four best models, what other criteria would you use to help in the selection of the best model? Discuss. 

One could look at the residual standard error for each model. The lower the error better. One could also at residual and QQ plots. If the plots indicate a transformation then that could prove to be the better model where as the R2ap will not account for it. 


### Case Study 9.29 <span id=recpoints>{10}</span><span id=report>{ 8 / 9 }</span> 

```{r}
# Code to read in the data
# It has to be merged from the 1.20 and 8.15 data files.
p9.29 <- read.table("http://www.stat.ufl.edu/~rrandles/sta4210/Rclassnotes/data/textdatasets/KutnerData/Appendix%20C%20Data%20Sets/APPENC06.txt", header=FALSE)

# Give it nice column names for conevience:
colnames(p9.29) <- c("ID","Y",paste("X",1:6, sep=""))

# Show the first part of the data:
#head(p9.29)

p29 <- p9.29
p29$X6 <- as.factor(p29$X6)
p29$X5 <- as.factor(p29$X5)
p29$X4 <- as.factor(p29$X4)
p29$X2 <- as.factor(p29$X2)
str(p29)
```

First we will look at a pairs plot. 

```{r}
pairs(p9.29)
```

All of them seem to have some promise. 

```{r}
makeTable9.3(p9.29)
```

X4 is always within one of the models so we will go with that to start off with. 

```{r}
p29.lm <- lm(Y ~ X4, data=p9.29)
summary(p29.lm)
plot(p29.lm, which=1)
plot(p29.lm, which=2)
```

X4 does show a lot of promise as being a useful variable. 

Normallity of the error terms is looking great but variance not so much. 

However, considering that this is just one variable that is qualitative it will not matter quite so much because using only X4 basically turns this an independent t test. 

```{r}
plot(Y ~ X4, data=p9.29, col=X4+1)
abline(5.4468, 0, col="black")
abline(5.4468 + 10.0917, 0, col="red")
```


```{r}
boxplot(Y~X4, data=p9.29)
favstats(Y ~ X4, data=p9.29)
```

Lets see if we can add more to this. 

```{r}
pairs(cbind(R=p29.lm$res, p9.29))
```

X1, X3 or X5 might be of some use. 

```{r}
plot(Y ~ X1, col=X4+1, data=p9.29)
```

Adding X1 into the picture with the color of X4 shows some interesting patterns. Unfortunatly we have an outlier that will porve to be an challenging. 

Lets fit X1 into the model with an interaction term. 

```{r}
p9.29.lm2 <- lm(Y ~ X1 + X4 + X1:X4, data=p9.29)
summary(p9.29.lm2)
plot(p9.29.lm2, which=1)
plot(p9.29.lm2, which=2)
```

The residuals still are not great. The outlier as caused the regression line to miss the data very badly. Adding X1 did not seem to have much of an effect. 

```{R}
plot(Y ~ X1, col=X4+1, data=p9.29)
b<- p9.29.lm2$coefficients
abline(b[1], b[2], col="black")
abline(b[1]+b[3], b[2]+b[4], col="red")
```

```{r}
p9.29.lm3 <- lm(Y ~ X4 + X1, data=p9.29)
summary(p9.29.lm3)
plot(p9.29.lm3, which=1)
plot(p9.29.lm3, which=2)
```

Leaving out the interaction term does not seem to much good either. 

Lets try X3

```{r}
p9.29.lm4 <- lm(Y ~ X4 + X3, data=p9.29)
summary(p9.29.lm4)
plot(p9.29.lm4, which=1)
plot(p9.29.lm4, which=2)
```

But that does not seem to add much either. 

This plot seems to be explain some things. 
```{r}
p9.29.lm6 <- lm(Y ~ X3 + X4 + X4:X3,data=p9.29)
plot(Y ~ X3, col=X4+1, data=p9.29)
b<- p9.29.lm6$coefficients
abline(b[1], b[2], col="black")
abline(b[1]+b[3], b[2]+b[4], col="red")
```

After quite a few other combinations this model seemed to work well. 

```{r}
p9.29.lm5 <- lm(Y ~ X3 + X1 + X4 + X3:X1, data=p9.29)
summary(p9.29.lm5)
plot(p9.29.lm5,which=1)
plot(p9.29.lm5,which=2)
```

```{r}
pairs(cbind(R=p9.29.lm5$res, p9.29), col=as.factor(p9.29$X4))
```

This has the highest R2a value with the lowest residual standard error. This model is far more complex than just using X4 alone. But the residuals indicate that a slight non linearity and non constant variance. A transformation may be able to fix that. 

Multicollinearity may be a problem in may model due to the high correlation between X1 and X3. 

The last may be able to predict it better than the first model but it will be far more difficult to interpret, if its possible to. 

It would be easier for a company to understand the first model compared to the later. 

X4 does seem to have the most influencal variable but other ones such as X1, X3 and X5 are also discriptive in some way. 

The correlation between X1 and X3 are interesting enough. 


### Case Study 9.30 <span id=points>{10}</span><span id=report>{ / }</span> 

```{r}
# Code to read in the data
# It has to be merged from the 1.20 and 8.15 data files.
p9.30 <- read.table("http://www.stat.ufl.edu/~rrandles/sta4210/Rclassnotes/data/textdatasets/KutnerData/Appendix%20C%20Data%20Sets/APPENC05.txt", header=FALSE)

# Give it nice column names for conevience:
colnames(p9.30) <- c("ID","Y",paste("X",1:7, sep=""))

# Show the first part of the data:
#head(p9.30)
```

</div>




<style>
#points {
  font-size:.8em;
  padding-left:5px;
  font-weight:bold; 
  color:#317eac;
}

#recpoints {
  font-size:.8em;
  padding-left:5px;
  font-weight:bold; 
  color:#7eac31;
}

#rrecpoints {
  font-size:1em;
  padding-left:5px;
  font-weight:bold; 
  color:#7eac31;
}

#report {
  font-size:.7em;
  padding-left:15px;
  font-weight:normal; 
  color:#5a5a5a;
}

#datalink {
  font-size:.5em;
  color:#317eac;
  padding-left:5px;
}

#headnote {
  font-size:.6em;
  color:#787878;
}

#note {
  font-size:.8em;
  color:#787878;
}

#headpoints {
 font-size:12pt;
 color: #585858; 
 padding-left: 15px;
}
</style>



<footer>
</footer>



 

 

 

 